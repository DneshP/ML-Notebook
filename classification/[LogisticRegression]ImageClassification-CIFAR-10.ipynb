{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bacef4f3",
   "metadata": {},
   "source": [
    "# Image Classification using Logistic Regression and LDA\n",
    "\n",
    "Welcome to this notebook, which explores image classification using the CIFAR-10 dataset. The primary goal is to demonstrate the use of Linear Discriminant Analysis (LDA) as a feature reduction technique and Logistic Regression as the classification model.\n",
    "\n",
    "The notebook presents an overview of the image classification process with LDA and Logistic Regression. Let's dive in!\n",
    "\n",
    "## Model Results\n",
    "\n",
    "- **Training Scores**: [0.540125, 0.536, 0.528375, 0.52925, 0.545375]\n",
    "- **Prediction Scores**: [3, 1, 5, ..., 8, 8, 8]\n",
    "- **Precision**: 0.534187034361574\n",
    "- **Recall**: 0.5357915163306523\n",
    "- **F1 Score**: 0.5346558723184491"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9ad422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# x_train and x_test contain the images, y_train and y_test contain the labels\n",
    "\n",
    "# Look at the shape\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e33f26-afb0-4154-bd3b-86c2f0f238d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, cross_val_predict, StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Stratified split is used to ensure that the distribution of classes in the training and holdout sets\n",
    "# closely reflects the original dataset, which helps maintain the actual probabilities of the dataset.\n",
    "\n",
    "stratified_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, holdout_index in stratified_split.split(x_train, y_train):\n",
    "    X_train, X_holdout = x_train[train_index], x_train[holdout_index]\n",
    "    Y_train, Y_holdout = y_train[train_index], y_train[holdout_index]\n",
    "\n",
    "X_train_flattened = np.array([image.flatten() for image in X_train])\n",
    "X_holdout_flattened = np.array([image.flatten() for image in X_holdout])\n",
    "Y_train_flat = Y_train.ravel()\n",
    "Y_holdout_flat = Y_holdout.ravel()\n",
    "\n",
    "# Normalise the data\n",
    "X_train_flattened = X_train_flattened / 255\n",
    "X_holdout_flattened = X_holdout_flattened / 255\n",
    "\n",
    "# Shape of the normalised data\n",
    "print('X_train shape:', X_train_flattened.shape)\n",
    "print('Y_train shape:', Y_train_flat.shape)\n",
    "print('X_holdout shape:', X_holdout_flattened.shape)\n",
    "print('Y_holdout shape:', Y_holdout_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a20a64a-eec0-4975-b2f0-5c8668190549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Discriminant Analysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "lda.fit(X_train_flattened, Y_train_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9a774f-58c9-4c9b-bb04-d26069b1943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "from sklearn.model_selection import cross_val_score, KFold, cross_val_predict\n",
    "\n",
    "# KFold cross-validation on training set\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "training_scores = cross_val_score(lda, X_train_flattened, Y_train_flat, cv=cv, scoring='accuracy')\n",
    "\n",
    "mean_score = training_scores.mean()\n",
    "std_score = training_scores.std()\n",
    "\n",
    "# Use cross_val_predict to obtain predictions for each sample within the training set\n",
    "training_predictions = cross_val_predict(lda, X_train_flattened, Y_train_flat, cv=cv, method='predict')\n",
    "training_recall = recall_score(Y_train_flat, training_predictions, average='macro')\n",
    "\n",
    "# Use the LDA model to predict on the holdout set\n",
    "holdout_predictions = lda.predict(X_holdout_flattened)\n",
    "holdout_recall = recall_score(Y_holdout_flat, holdout_predictions, average='macro')\n",
    "\n",
    "print('LDA training scores:', training_scores)\n",
    "print('LDA Training Recall:', training_recall)\n",
    "print('LDA Holdout Recall:', holdout_recall)\n",
    "print('STD', std_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1623dd-908e-46a3-b357-2b9a469dfcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the LDA to tranform the data for feature reduction\n",
    "\n",
    "# Applying Transform\n",
    "X_train_reduced = lda.transform(X_train_flattened)\n",
    "print(X_train_reduced)\n",
    "\n",
    "# shape of the reduced data\n",
    "print(X_train_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef216b9-fea7-4277-b0d4-03ad48176368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train = X_train_reduced.copy()\n",
    "y_train = Y_train_flat.copy()\n",
    "\n",
    "# Choosing the model\n",
    "lrModel = LogisticRegression(max_iter=100)\n",
    "\n",
    "# Fit the model on the entire training set\n",
    "lrModel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7658e93b-98f3-4f3a-bd6d-f49bca3e91fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold, cross_val_predict\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Cross-validation method within the training set\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation within the training set\n",
    "training_scores = cross_val_score(lrModel, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# You can also calculate the mean and standard deviation of the scores\n",
    "mean_score = training_scores.mean()\n",
    "std_score = training_scores.std()\n",
    "\n",
    "# Use cross_val_predict to obtain predictions for each sample within the training set\n",
    "training_predictions = cross_val_predict(lrModel, X_train, y_train, cv=cv, method='predict')\n",
    "training_recall = recall_score(Y_train_flat, training_predictions, average='macro')\n",
    "training_precision = precision_score(Y_train_flat, training_predictions, average='macro')\n",
    "training_f1 = f1_score(Y_train_flat, training_predictions, average='macro')\n",
    "\n",
    "# Use the Logistic Regression model to predict on the holdout set\n",
    "# Transform the holdout set using the trained LDA\n",
    "\n",
    "X_holdout_reduced = lda.transform(X_holdout_flattened)\n",
    "\n",
    "holdout_predictions = lrModel.predict(X_holdout_reduced)\n",
    "\n",
    "# Get predicted probabilities\n",
    "predicted_probabilities = lrModel.predict_proba(X_holdout_reduced)[:, 1]\n",
    "\n",
    "# Set the threshold value to 0.8 for higher precision, low recall\n",
    "# Set a lower threshold value for higher recall, lower precision\n",
    "threshold = 0.5\n",
    "\n",
    "# Predictions based on the threshold\n",
    "threshold_predictions = (predicted_probabilities >= threshold).astype(int)\n",
    "\n",
    "holdout_recall = recall_score(Y_holdout_flat, threshold_predictions, average='macro')\n",
    "holdout_precision = precision_score(Y_holdout_flat, threshold_predictions, average='macro')\n",
    "holdout_f1 = f1_score(Y_holdout_flat, threshold_predictions, average='macro')\n",
    "\n",
    "print('Training scores:', training_scores)\n",
    "print('Training Recall:', training_recall)\n",
    "print('Training Precision:', training_precision)\n",
    "print('Training F1 Score:', training_f1)\n",
    "print('Holdout Recall:', holdout_recall)\n",
    "print('Holdout Precision:', holdout_precision)\n",
    "print('Holdout F1 Score:', holdout_f1)\n",
    "print('STD', std_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
