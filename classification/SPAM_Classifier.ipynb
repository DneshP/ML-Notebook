{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "SPAM classifier"
      ],
      "metadata": {
        "id": "2sNIaKYjVvwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "import tarfile\n",
        "from pathlib import Path\n",
        "import urllib.request\n",
        "import urllib.parse\n",
        "\n",
        "\n",
        "def fetch_spam_data():\n",
        "    spam_root = \"http://spamassassin.apache.org/old/publiccorpus/\"\n",
        "    ham_url = spam_root + \"20030228_easy_ham.tar.bz2\"\n",
        "    spam_url = spam_root + \"20030228_spam.tar.bz2\"\n",
        "\n",
        "    spam_path = Path() / \"datasets\" / \"spam\"\n",
        "    spam_path.mkdir(parents=True, exist_ok=True)\n",
        "    for dir_name, tar_name, url in ((\"easy_ham\", \"ham\", ham_url),\n",
        "                                    (\"spam\", \"spam\", spam_url)):\n",
        "        if not (spam_path / dir_name).is_dir():\n",
        "            path = (spam_path / tar_name).with_suffix(\".tar.bz2\")\n",
        "            print(\"Downloading\", path)\n",
        "            urllib.request.urlretrieve(url, path)\n",
        "            tar_bz2_file = tarfile.open(path)\n",
        "            tar_bz2_file.extractall(path=spam_path)\n",
        "            tar_bz2_file.close()\n",
        "    return [spam_path / dir_name for dir_name in (\"easy_ham\", \"spam\")]"
      ],
      "metadata": {
        "id": "kLiLolJGVzQM"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ham_dir, spam_dir = fetch_spam_data()"
      ],
      "metadata": {
        "id": "ZqT8QNsucC4i"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the emails\n",
        "ham_filenames = [f for f in sorted(ham_dir.iterdir()) if len(f.name) > 20]\n",
        "spam_filenames = [f for f in sorted(spam_dir.iterdir()) if len(f.name) > 20]"
      ],
      "metadata": {
        "id": "IIuprOeVZnCf"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse emails\n",
        "import email\n",
        "import email.policy\n",
        "\n",
        "def load_email(filepath):\n",
        "    with open(filepath, \"rb\") as f:\n",
        "        return email.parser.BytesParser(policy=email.policy.default).parse(f)"
      ],
      "metadata": {
        "id": "iV7q8-5Sc7WP"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ham_emails = [load_email(filepath) for filepath in ham_filenames]\n",
        "spam_emails = [load_email(filepath) for filepath in spam_filenames]"
      ],
      "metadata": {
        "id": "bIbGaBQLdFyD"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualise the parsed content\n",
        "# print(ham_emails[1].get_content().strip())\n",
        "print(spam_emails[1].get_content().strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kdp-IJXwdLTC",
        "outputId": "6c6e69be-153e-4fd7-fdce-943c4f6a622c"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1) Fight The Risk of Cancer!\n",
            "http://www.adclick.ws/p.cfm?o=315&s=pk007\n",
            "\n",
            "2) Slim Down - Guaranteed to lose 10-12 lbs in 30 days\n",
            "http://www.adclick.ws/p.cfm?o=249&s=pk007\n",
            "\n",
            "3) Get the Child Support You Deserve - Free Legal Advice\n",
            "http://www.adclick.ws/p.cfm?o=245&s=pk002\n",
            "\n",
            "4) Join the Web's Fastest Growing Singles Community\n",
            "http://www.adclick.ws/p.cfm?o=259&s=pk007\n",
            "\n",
            "5) Start Your Private Photo Album Online!\n",
            "http://www.adclick.ws/p.cfm?o=283&s=pk007\n",
            "\n",
            "Have a Wonderful Day,\n",
            "Offer Manager\n",
            "PrizeMama\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "If you wish to leave this list please use the link below.\n",
            "http://www.qves.com/trim/?ilug@linux.ie%7C17%7C114258\n",
            "\n",
            "\n",
            "-- \n",
            "Irish Linux Users' Group: ilug@linux.ie\n",
            "http://www.linux.ie/mailman/listinfo/ilug for (un)subscription information.\n",
            "List maintainer: listmaster@linux.ie\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyse the structure of the email\n",
        "def get_email_structure(email):\n",
        "    if isinstance(email, str):\n",
        "        return email\n",
        "    payload = email.get_payload()\n",
        "    if isinstance(payload, list):\n",
        "        multipart = \", \".join([get_email_structure(sub_email)\n",
        "                               for sub_email in payload])\n",
        "        return f\"multipart({multipart})\"\n",
        "    else:\n",
        "        return email.get_content_type()"
      ],
      "metadata": {
        "id": "n61PsSXAgzGu"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def structures_counter(emails):\n",
        "    structures = Counter()\n",
        "    for email in emails:\n",
        "        structure = get_email_structure(email)\n",
        "        structures[structure] += 1\n",
        "    return structures"
      ],
      "metadata": {
        "id": "eKLuv4xTg9wG"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ham email structure\n",
        "structures_counter(ham_emails).most_common()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFpH0OckhXuE",
        "outputId": "6b602edb-ae68-4410-ff7a-4390071db24f"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('text/plain', 2408),\n",
              " ('multipart(text/plain, application/pgp-signature)', 66),\n",
              " ('multipart(text/plain, text/html)', 8),\n",
              " ('multipart(text/plain, text/plain)', 4),\n",
              " ('multipart(text/plain)', 3),\n",
              " ('multipart(text/plain, application/octet-stream)', 2),\n",
              " ('multipart(text/plain, text/enriched)', 1),\n",
              " ('multipart(text/plain, application/ms-tnef, text/plain)', 1),\n",
              " ('multipart(multipart(text/plain, text/plain, text/plain), application/pgp-signature)',\n",
              "  1),\n",
              " ('multipart(text/plain, video/mng)', 1),\n",
              " ('multipart(text/plain, multipart(text/plain))', 1),\n",
              " ('multipart(text/plain, application/x-pkcs7-signature)', 1),\n",
              " ('multipart(text/plain, multipart(text/plain, text/plain), text/rfc822-headers)',\n",
              "  1),\n",
              " ('multipart(text/plain, multipart(text/plain, text/plain), multipart(multipart(text/plain, application/x-pkcs7-signature)))',\n",
              "  1),\n",
              " ('multipart(text/plain, application/x-java-applet)', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Spam email structure\n",
        "structures_counter(spam_emails).most_common()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksJUY979heoB",
        "outputId": "0c3910dd-0752-49b0-b725-ad51d262c9cd"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('text/plain', 218),\n",
              " ('text/html', 183),\n",
              " ('multipart(text/plain, text/html)', 45),\n",
              " ('multipart(text/html)', 20),\n",
              " ('multipart(text/plain)', 19),\n",
              " ('multipart(multipart(text/html))', 5),\n",
              " ('multipart(text/plain, image/jpeg)', 3),\n",
              " ('multipart(text/html, application/octet-stream)', 2),\n",
              " ('multipart(text/plain, application/octet-stream)', 1),\n",
              " ('multipart(text/html, text/plain)', 1),\n",
              " ('multipart(multipart(text/html), application/octet-stream, image/jpeg)', 1),\n",
              " ('multipart(multipart(text/plain, text/html), image/gif)', 1),\n",
              " ('multipart/alternative', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Header data: Spam\n",
        "for header, value in spam_emails[0].items():\n",
        "    print(header, \":\", value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgqvZdGQhufW",
        "outputId": "187eaaa4-8340-4d05-86d8-85bd4a2e482c"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Return-Path : <12a1mailbot1@web.de>\n",
            "Delivered-To : zzzz@localhost.spamassassin.taint.org\n",
            "Received : from localhost (localhost [127.0.0.1])\tby phobos.labs.spamassassin.taint.org (Postfix) with ESMTP id 136B943C32\tfor <zzzz@localhost>; Thu, 22 Aug 2002 08:17:21 -0400 (EDT)\n",
            "Received : from mail.webnote.net [193.120.211.219]\tby localhost with POP3 (fetchmail-5.9.0)\tfor zzzz@localhost (single-drop); Thu, 22 Aug 2002 13:17:21 +0100 (IST)\n",
            "Received : from dd_it7 ([210.97.77.167])\tby webnote.net (8.9.3/8.9.3) with ESMTP id NAA04623\tfor <zzzz@spamassassin.taint.org>; Thu, 22 Aug 2002 13:09:41 +0100\n",
            "From : 12a1mailbot1@web.de\n",
            "Received : from r-smtp.korea.com - 203.122.2.197 by dd_it7  with Microsoft SMTPSVC(5.5.1775.675.6);\t Sat, 24 Aug 2002 09:42:10 +0900\n",
            "To : dcek1a1@netsgo.com\n",
            "Subject : Life Insurance - Why Pay More?\n",
            "Date : Wed, 21 Aug 2002 20:31:57 -1600\n",
            "MIME-Version : 1.0\n",
            "Message-ID : <0103c1042001882DD_IT7@dd_it7>\n",
            "Content-Type : text/html; charset=\"iso-8859-1\"\n",
            "Content-Transfer-Encoding : quoted-printable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Header data: Ham\n",
        "for header, value in ham_emails[0].items():\n",
        "    print(header, \":\", value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtwmDABIhzDh",
        "outputId": "ec293110-56d2-456c-ca08-96f30e9c7fff"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Return-Path : <exmh-workers-admin@spamassassin.taint.org>\n",
            "Delivered-To : zzzz@localhost.netnoteinc.com\n",
            "Received : from localhost (localhost [127.0.0.1])\tby phobos.labs.netnoteinc.com (Postfix) with ESMTP id D03E543C36\tfor <zzzz@localhost>; Thu, 22 Aug 2002 07:36:16 -0400 (EDT)\n",
            "Received : from phobos [127.0.0.1]\tby localhost with IMAP (fetchmail-5.9.0)\tfor zzzz@localhost (single-drop); Thu, 22 Aug 2002 12:36:16 +0100 (IST)\n",
            "Received : from listman.spamassassin.taint.org (listman.spamassassin.taint.org [66.187.233.211]) by    dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g7MBYrZ04811 for    <zzzz-exmh@spamassassin.taint.org>; Thu, 22 Aug 2002 12:34:53 +0100\n",
            "Received : from listman.spamassassin.taint.org (localhost.localdomain [127.0.0.1]) by    listman.redhat.com (Postfix) with ESMTP id 8386540858; Thu, 22 Aug 2002    07:35:02 -0400 (EDT)\n",
            "Delivered-To : exmh-workers@listman.spamassassin.taint.org\n",
            "Received : from int-mx1.corp.spamassassin.taint.org (int-mx1.corp.spamassassin.taint.org    [172.16.52.254]) by listman.redhat.com (Postfix) with ESMTP id 10CF8406D7    for <exmh-workers@listman.redhat.com>; Thu, 22 Aug 2002 07:34:10 -0400    (EDT)\n",
            "Received : (from mail@localhost) by int-mx1.corp.spamassassin.taint.org (8.11.6/8.11.6)    id g7MBY7g11259 for exmh-workers@listman.redhat.com; Thu, 22 Aug 2002    07:34:07 -0400\n",
            "Received : from mx1.spamassassin.taint.org (mx1.spamassassin.taint.org [172.16.48.31]) by    int-mx1.corp.redhat.com (8.11.6/8.11.6) with SMTP id g7MBY7Y11255 for    <exmh-workers@redhat.com>; Thu, 22 Aug 2002 07:34:07 -0400\n",
            "Received : from ratree.psu.ac.th ([202.28.97.6]) by mx1.spamassassin.taint.org    (8.11.6/8.11.6) with SMTP id g7MBIhl25223 for <exmh-workers@redhat.com>;    Thu, 22 Aug 2002 07:18:55 -0400\n",
            "Received : from delta.cs.mu.OZ.AU (delta.coe.psu.ac.th [172.30.0.98]) by    ratree.psu.ac.th (8.11.6/8.11.6) with ESMTP id g7MBWel29762;    Thu, 22 Aug 2002 18:32:40 +0700 (ICT)\n",
            "Received : from munnari.OZ.AU (localhost [127.0.0.1]) by delta.cs.mu.OZ.AU    (8.11.6/8.11.6) with ESMTP id g7MBQPW13260; Thu, 22 Aug 2002 18:26:25    +0700 (ICT)\n",
            "From : Robert Elz <kre@munnari.OZ.AU>\n",
            "To : Chris Garrigues <cwg-dated-1030377287.06fa6d@DeepEddy.Com>\n",
            "Cc : exmh-workers@spamassassin.taint.org\n",
            "Subject : Re: New Sequences Window\n",
            "In-Reply-To : <1029945287.4797.TMDA@deepeddy.vircio.com>\n",
            "References : <1029945287.4797.TMDA@deepeddy.vircio.com>    <1029882468.3116.TMDA@deepeddy.vircio.com> <9627.1029933001@munnari.OZ.AU>    <1029943066.26919.TMDA@deepeddy.vircio.com>    <1029944441.398.TMDA@deepeddy.vircio.com>\n",
            "MIME-Version : 1.0\n",
            "Content-Type : text/plain; charset=\"us-ascii\"\n",
            "Message-Id : <13258.1030015585@munnari.OZ.AU>\n",
            "X-Loop : exmh-workers@spamassassin.taint.org\n",
            "Sender : exmh-workers-admin@spamassassin.taint.org\n",
            "Errors-To : exmh-workers-admin@spamassassin.taint.org\n",
            "X-Beenthere : exmh-workers@spamassassin.taint.org\n",
            "X-Mailman-Version : 2.0.1\n",
            "Precedence : bulk\n",
            "List-Help : <mailto:exmh-workers-request@spamassassin.taint.org?subject=help>\n",
            "List-Post : <mailto:exmh-workers@spamassassin.taint.org>\n",
            "List-Subscribe : <https://listman.spamassassin.taint.org/mailman/listinfo/exmh-workers>,    <mailto:exmh-workers-request@redhat.com?subject=subscribe>\n",
            "List-Id : Discussion list for EXMH developers <exmh-workers.spamassassin.taint.org>\n",
            "List-Unsubscribe : <https://listman.spamassassin.taint.org/mailman/listinfo/exmh-workers>,    <mailto:exmh-workers-request@redhat.com?subject=unsubscribe>\n",
            "List-Archive : <https://listman.spamassassin.taint.org/mailman/private/exmh-workers/>\n",
            "Date : Thu, 22 Aug 2002 18:26:25 +0700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = np.array(ham_emails + spam_emails, dtype=object)\n",
        "y = np.array([0] * len(ham_emails) + [1] * len(spam_emails))\n",
        "print(y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    random_state=42)"
      ],
      "metadata": {
        "id": "NxvtMMz6iDwW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b7b1102-79d2-4cc7-dce9-a3ff6f97e627"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3p5-tiGiNEG",
        "outputId": "05144962-31f2-4d4b-9a99-e54db4cea21c"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2400,)\n",
            "Return-Path: <fork-admin@xent.com>\n",
            "Delivered-To: yyyy@localhost.spamassassin.taint.org\n",
            "Received: from localhost (jalapeno [127.0.0.1])\n",
            "\tby jmason.org (Postfix) with ESMTP id DEA8516F03\n",
            "\tfor <jm@localhost>; Thu, 19 Sep 2002 13:26:35 +0100 (IST)\n",
            "Received: from jalapeno [127.0.0.1]\n",
            "\tby localhost with IMAP (fetchmail-5.9.0)\n",
            "\tfor jm@localhost (single-drop); Thu, 19 Sep 2002 13:26:35 +0100 (IST)\n",
            "Received: from xent.com ([64.161.22.236]) by dogma.slashnull.org\n",
            "    (8.11.6/8.11.6) with ESMTP id g8JCFfC18989 for <jm@jmason.org>;\n",
            "    Thu, 19 Sep 2002 13:15:42 +0100\n",
            "Received: from lair.xent.com (localhost [127.0.0.1]) by xent.com (Postfix)\n",
            "    with ESMTP id B101E294108; Thu, 19 Sep 2002 05:12:05 -0700 (PDT)\n",
            "Delivered-To: fork@spamassassin.taint.org\n",
            "Received: from argote.ch (argote.ch [80.65.224.17]) by xent.com (Postfix)\n",
            "    with ESMTP id 19FF329409E for <fork@xent.com>; Thu, 19 Sep 2002 05:11:32\n",
            "    -0700 (PDT)\n",
            "Received: by argote.ch (Postfix, from userid 500) id CA1F9C44D;\n",
            "    Thu, 19 Sep 2002 14:14:06 +0200 (CEST)\n",
            "To: fork@spamassassin.taint.org\n",
            "Subject: Re: Hanson's Sept 11 message in the National Review\n",
            "Message-Id: <20020919121406.CA1F9C44D@argote.ch>\n",
            "From: harley@argote.ch (Robert Harley)\n",
            "Sender: fork-admin@xent.com\n",
            "Errors-To: fork-admin@xent.com\n",
            "X-Beenthere: fork@spamassassin.taint.org\n",
            "X-Mailman-Version: 2.0.11\n",
            "Precedence: bulk\n",
            "List-Help: <mailto:fork-request@xent.com?subject=help>\n",
            "List-Post: <mailto:fork@spamassassin.taint.org>\n",
            "List-Subscribe: <http://xent.com/mailman/listinfo/fork>,\n",
            " <mailto:fork-request@xent.com?subject=subscribe>\n",
            "List-Id: Friends of Rohit Khare <fork.xent.com>\n",
            "List-Unsubscribe: <http://xent.com/mailman/listinfo/fork>,\n",
            "    <mailto:fork-request@xent.com?subject=unsubscribe>\n",
            "List-Archive: <http://xent.com/pipermail/fork/>\n",
            "Date: Thu, 19 Sep 2002 14:14:06 +0200 (CEST)\n",
            "\n",
            "Chuck Murcko wrote:\n",
            ">[...stuff...]\n",
            "\n",
            "Yawn.\n",
            "\n",
            "R\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the html email to plain text\n",
        "import re\n",
        "from html import unescape\n",
        "\n",
        "def html_to_plain_text(html):\n",
        "    text = re.sub('<head.*?>.*?</head>', '', html, flags=re.M | re.S | re.I)\n",
        "    text = re.sub('<a\\s.*?>', ' HYPERLINK ', text, flags=re.M | re.S | re.I)\n",
        "    text = re.sub('<.*?>', '', text, flags=re.M | re.S)\n",
        "    text = re.sub(r'(\\s*\\n)+', '\\n', text, flags=re.M | re.S)\n",
        "    return unescape(text)\n",
        "\n",
        "def email_to_text(email):\n",
        "    html = None\n",
        "    for part in email.walk():\n",
        "        ctype = part.get_content_type()\n",
        "        if not ctype in (\"text/plain\", \"text/html\"):\n",
        "            continue\n",
        "        try:\n",
        "            content = part.get_content()\n",
        "        except: # in case of encoding issues\n",
        "            content = str(part.get_payload())\n",
        "        if ctype == \"text/plain\":\n",
        "            return content\n",
        "        else:\n",
        "            html = content\n",
        "    if html:\n",
        "        return html_to_plain_text(html)"
      ],
      "metadata": {
        "id": "l1RN9B48jDaK"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# url extractor\n",
        "\n",
        "%pip install -q -U urlextract\n",
        "import urlextract\n",
        "\n",
        "url_extractor = urlextract.URLExtract()"
      ],
      "metadata": {
        "id": "n5-4QseHjnE2"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stemming\n",
        "import nltk\n",
        "\n",
        "stemmer = nltk.PorterStemmer()\n",
        "for word in (\"Computations\", \"Computation\", \"Computing\", \"Computed\", \"Compute\",\n",
        "             \"Compulsive\"):\n",
        "    print(word, \"=>\", stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_uXJ_YSmyXb",
        "outputId": "9324280f-e283-494f-9ae6-cc35c2ce60bd"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computations => comput\n",
            "Computation => comput\n",
            "Computing => comput\n",
            "Computed => comput\n",
            "Compute => comput\n",
            "Compulsive => compuls\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a custom transformer\n",
        "\n",
        "# split the email into words\n",
        "# replace the url content with the word URL\n",
        "# remove noise (ex: grammar)\n",
        "# convert to lower_case\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class EmailToWordCounterTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, strip_headers=True, lower_case=True,\n",
        "                 remove_punctuation=True, replace_urls=True,\n",
        "                 replace_numbers=True, stemming=True):\n",
        "        self.strip_headers = strip_headers\n",
        "        self.lower_case = lower_case\n",
        "        self.remove_punctuation = remove_punctuation\n",
        "        self.replace_urls = replace_urls\n",
        "        self.replace_numbers = replace_numbers\n",
        "        self.stemming = stemming\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X, y=None):\n",
        "        X_transformed = []\n",
        "        for email in X:\n",
        "            text = email_to_text(email) or \"\"\n",
        "            if self.lower_case:\n",
        "                text = text.lower()\n",
        "            if self.replace_urls and url_extractor is not None:\n",
        "                urls = list(set(url_extractor.find_urls(text)))\n",
        "                urls.sort(key=lambda url: len(url), reverse=True)\n",
        "                for url in urls:\n",
        "                    text = text.replace(url, \" URL \")\n",
        "            if self.replace_numbers:\n",
        "                text = re.sub(r'\\d+(?:\\.\\d*)?(?:[eE][+-]?\\d+)?', 'NUMBER', text)\n",
        "            if self.remove_punctuation:\n",
        "                text = re.sub(r'\\W+', ' ', text, flags=re.M)\n",
        "            word_counts = Counter(text.split())\n",
        "            if self.stemming and stemmer is not None:\n",
        "                stemmed_word_counts = Counter()\n",
        "                for word, count in word_counts.items():\n",
        "                    stemmed_word = stemmer.stem(word)\n",
        "                    stemmed_word_counts[stemmed_word] += count\n",
        "                word_counts = stemmed_word_counts\n",
        "            X_transformed.append(word_counts)\n",
        "        return np.array(X_transformed)"
      ],
      "metadata": {
        "id": "nxxulWfxkfJh"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # output of the transformer (vocabulary)\n",
        "# email_to_word_transformer = EmailToWordCounterTransformer()\n",
        "# X_train_email_to_words = email_to_word_transformer.fit_transform(X_train[:5])"
      ],
      "metadata": {
        "id": "X68Tc4Wk92cX"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a vector from the transformed data\n",
        "# idea is to create a vector for each word\n",
        "# create a row for each email word counts\n",
        "# for example ([Counter({'chuck': 1, 'murcko': 1, 'wrote': 1, 'stuff': 1, 'yawn': 1, 'r': 1}))\n",
        "# Counter({'the': 11, 'murcko': 9, 'and': 8, 'all': 3, 'christian': 3, 'to': 3, 'by': 3,\n",
        "# the best i can imagine is each email will be a row and the word will be the columns and the value(saclar) will the occurance\n",
        "# [\n",
        "#   [1,], [1,], [1,], [1,], [1,], [1,],\n",
        "#   [0,], [9,], [0,], [0,], [0,], [0,],\n",
        "#   # ...\n",
        "# ]\n",
        "# from sklearn.pipeline import Pipeline\n",
        "\n",
        "# vocabulary = output[0].keys()\n",
        "# count_vectorise = TfidfVectorizer(vocabulary=vocabulary)\n",
        "# email_data = X_train[:1]\n",
        "\n",
        "\n",
        "# vectorise_pipeline = Pipeline(\n",
        "#     [\n",
        "#         ('count_vectorise', count_vectorise)\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "# email_contents = [email.get_content() for email in email_data]\n",
        "\n",
        "# output_vectorised = vectorise_pipeline.fit_transform(email_contents)\n",
        "\n",
        "# # output_vectorised = vectorise.fit_transform(output)\n",
        "# print(output)\n",
        "# print(output_vectorised)\n"
      ],
      "metadata": {
        "id": "KnLDk2njASlt"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have the word counts, and we need to convert them to vectors. For this, we will build another transformer whose fit() method will build the vocabulary (an ordered list of the most common words) and whose transform() method will use the vocabulary to convert word counts to vectors. The output is a sparse matrix."
      ],
      "metadata": {
        "id": "jNguvaNWF7N4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a custom transformer for vectorisation\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from collections import Counter\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "class VectoriseEmailTransformer(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self, vocabulary_size=1000):\n",
        "    self.vocabulary_size = vocabulary_size\n",
        "\n",
        "  def fit(self, X, y=None):\n",
        "    total_count = Counter()\n",
        "    for word_count in X:\n",
        "      for word, count in word_count.items():\n",
        "        total_count[word] += min(count, 10) # limt the max count\n",
        "    most_common = total_count.most_common()[:self.vocabulary_size]\n",
        "\n",
        "    self.vocabulary_ = {word: index + 1\n",
        "                            for index, (word, count) in enumerate(most_common)}\n",
        "\n",
        "    return self\n",
        "\n",
        "  def transform(self, X, y=None):\n",
        "    rows = []\n",
        "    columns = []\n",
        "    data = []\n",
        "    for row, word_count in enumerate(X):\n",
        "      for word, count in word_count.items():\n",
        "        rows.append(row)\n",
        "        columns.append(self.vocabulary_.get(word, 0))\n",
        "        data.append(count)\n",
        "    return csr_matrix((data, (rows, columns)), shape=(len(X), self.vocabulary_size + 1))\n",
        ""
      ],
      "metadata": {
        "id": "chlucvlLMmJX"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vectorise_email = VectoriseEmailTransformer(vocabulary_size=10)\n",
        "# X_few_vectors = vectorise_email.fit_transform(X_train_email_to_words)\n",
        "# print(X_few_vectors.toarray())\n",
        "# print(X_train_email_to_words[0])\n",
        "# print(X[0])"
      ],
      "metadata": {
        "id": "hWMLvOSlHv9j"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline for email transformation\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "steps = {\n",
        "    ('email_to_words', EmailToWordCounterTransformer()),\n",
        "    ('vectorised_email', VectoriseEmailTransformer())\n",
        "}\n",
        "\n",
        "pipeline = Pipeline(steps)\n",
        "\n",
        "email_transformed = pipeline.fit_transform(X_train)"
      ],
      "metadata": {
        "id": "JwPEq65hdZWz"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "au3L1btPfKmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "X_test_transformed = pipeline.transform(X_test)\n",
        "X_train_transformed = pipeline.transform(X_train)\n",
        "log_clf = LogisticRegression(max_iter=1000, random_state=42)\n",
        "log_clf.fit(X_train_transformed, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WcJOuJvfZAX",
        "outputId": "3f77e03e-d9b0-4131-9637-40b06f487e44"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 96.88%\n",
            "Recall: 97.89%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scoring\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "scoring = {\n",
        "    'accuracy': make_scorer(accuracy_score),\n",
        "    'precision': make_scorer(precision_score, average='weighted'),\n",
        "    'recall': make_scorer(recall_score, average='weighted'),\n",
        "    'f1': make_scorer(f1_score, average='weighted')\n",
        "}\n",
        "results = cross_validate(log_clf, X_test_transformed, y_test, cv=5, scoring=scoring, return_train_score=True)\n",
        "\n",
        "accuracy_scores = results['test_accuracy']\n",
        "precision_scores = results['test_precision']\n",
        "recall_scores = results['test_recall']\n",
        "f1_scores = results['test_f1']\n",
        "\n",
        "\n",
        "print(f'Accuracy scores: {accuracy_scores}')\n",
        "print(f'Precision scores: {precision_scores}')\n",
        "print(f'Recall scores: {recall_scores}')\n",
        "print(f'F1 scores: {f1_scores}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEYUosC1gEA8",
        "outputId": "2b17894c-e61c-4209-f202-e005a16fdaf9"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy scores: [1.         0.975      0.95       0.95833333 0.95833333]\n",
            "Precision scores: [1.         0.97572115 0.9528379  0.95773237 0.95941667]\n",
            "Recall scores: [1.         0.975      0.95       0.95833333 0.95833333]\n",
            "F1 scores: [1.         0.9741115  0.951      0.9568525  0.95876387]\n"
          ]
        }
      ]
    }
  ]
}